# Using Hive Metastore (embedded) for simple Parquet reading
connector.name=hive-hadoop2
hive.metastore=file
hive.metastore.catalog.dir=/data/warehouse
hive.non-managed-table-writes-enabled=true
hive.allow-drop-table=true

# S3 / MinIO Support
# Credentials are injected at runtime via environment variable substitution.
# See docker-compose.yml entrypoint for envsubst usage.
hive.s3.endpoint=http://minio:9000
hive.s3.aws-access-key=${S3_ACCESS_KEY}
hive.s3.aws-secret-key=${S3_SECRET_KEY}
hive.s3.path-style-access=true
hive.s3.ssl.enabled=false
